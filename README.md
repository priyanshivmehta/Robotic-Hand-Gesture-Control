# ğŸ¦¾ Robotic Hand Gesture Control

Control a **5-DOF simulated robotic hand** in real-time using your webcam!  
This project combines **computer vision (MediaPipe)** and **physics simulation (MuJoCo)** to let a robot hand imitate your **fist open/close** gestures instantly.  

---

## âœ¨ Features
- ğŸ¯ Real-time hand gesture detection (open/close)
- ğŸ¦¿ Shadow Hand physics simulation using **MuJoCo**
- âš™ï¸ Smooth transition animation between gestures
- ğŸ§  Fully integrated â€” vision + control in one script
- ğŸ”Œ Easily extendable for real robotic hand hardware (e.g., CISMR arm)

---

## ğŸ—‚ï¸ Project Structure

Robotic-Hand-Gesture-Control/
â”‚
â”œâ”€â”€ mujoco_menagerie/
â”‚ â””â”€â”€ shadow_hand/
â”‚ â”œâ”€â”€ right_hand.xml
â”‚ â”œâ”€â”€ assets/
â”‚ â””â”€â”€ (other MuJoCo model files)
â”‚
â”œâ”€â”€ gesture.py # Main script (vision + simulation)
â”œâ”€â”€ requirements.txt # Dependencies
â””â”€â”€ README.md

yaml
Copy code

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/priyanshivmehta/Robotic-Hand-Gesture-Control.git
cd Robotic-Hand-Gesture-Control
```
### 2ï¸âƒ£ Create and Activate a Virtual Environment
Use Python 3.10 or 3.11 (avoid 3.12 for MediaPipe compatibility).

```bash
Copy code
py -3.10 -m venv cv
cv\Scripts\activate          # On Windows
# or
source cv/bin/activate       # On macOS/Linux
```
### 3ï¸âƒ£ Install Required Libraries
```bash
Copy code
pip install --upgrade pip
pip install -r requirements.txt
If you donâ€™t have a requirements.txt, create one with:

txt
Copy code
opencv-python
mediapipe
mujoco
numpy
```
### 4ï¸âƒ£ Download the MuJoCo Menagerie (if not included)
Copy code
```bash
git clone https://github.com/google-deepmind/mujoco_menagerie.git
```
Then copy the folder:

```bash
Copy code
mujoco_menagerie/shadow_hand/
into your project directory.
```
Make sure this file exists:

```bash
Copy code
mujoco_menagerie/shadow_hand/right_hand.xml
```
ğŸš€ Running the Simulation
Start the gesture control simulation with:

```bash
Copy code
python gesture.py
```
Two windows will open:

ğŸ¥ Webcam Feed â€“ detects your real-time hand gesture

ğŸ¦¿ MuJoCo Viewer â€“ robotic hand follows your gesture

Gesture	Simulation
ğŸ–ï¸ Open palm	Hand opens
âœŠ Closed fist	Hand closes

Press ESC to exit.

## ğŸ› ï¸ Hardware Requirements

To build the physical robotic arm as detailed in the project presentation:

### **Components List**
| Component | Description |
| :--- | :--- |
| **Arduino Nano** | Acts as the main microcontroller to read commands and control servos. |
| **Micro Servo Motors** | 5 motors (one for each finger). |
| **3D Printed Hand** | Custom or InMoov standard parts. |
| **Fishing Lines** | Acts as tendons to connect the fingers to the motors. |
| **Breadboard** | Used for power distribution. |
| **Power Supply** | External 5V supply recommended for servos. |

### **3D Printing & Assembly**
* **Material:** PLA+ or PETG is recommended for structural integrity.
* **Tendons:** Thread fishing lines through the 3D-printed fingers and tie them to the servo horns. Ensure the line is taut when the servo is at 0 degrees (Open position).

---

## âš¡ Circuit Connections

### **Wiring**
1.  **Servos to Arduino:** Connect the signal pins of the 5 servos to the Arduino PWM-enabled pins (e.g., D3, D5, D6, D9, D10).
2.  **Power Distribution (Breadboard):**
    * **Upper Horizontal Rail:** Connect to the **+5V** external power source (Powers all servo motors).
    * **Lower Horizontal Rail:** Connect to **Ground**.
    * **Common Ground:** **Important:** Connect the Arduino GND to the external power source GND to complete the circuit.

---

## ğŸ”Œ Hardware Setup (Arduino)

1.  Connect your Arduino Nano to your PC via USB.
2.  Upload the control sketch (e.g., `hardware/arduino_code/hand_control.ino`) to the board.
3.  **Running with Hardware:**
    * Update your Python controller script with the correct `COM_PORT` (e.g., `COM3` or `/dev/ttyUSB0`).
    * Run the script to start sending serial data to the Arduino.
